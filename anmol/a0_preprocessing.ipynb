{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23544ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install liac-arff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52943bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy liac-arff scikit-learn matplotlib seaborn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arff\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"All imports are working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d249fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "path = Path(\"../data/datasetone.csv\")  # even if extension says .csv\n",
    "with open(path, \"r\") as f:\n",
    "    raw = arff.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw[\"data\"], columns=[a[0] for a in raw[\"attributes\"]])\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf63015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/datasetone_fixed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/datasetone_fixed.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b73c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9cfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc38318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c627f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numeric:\", num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad5a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018fddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns detected earlier\n",
    "categorical = cat_cols\n",
    "numeric = num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8837b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputers + encoders\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd192d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric),\n",
    "        (\"cat\", categorical_transformer, categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Preprocessor ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "target =  \"Violation.Type\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69198e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute feature lists from X (target already dropped)\n",
    "categorical = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric     = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "\n",
    "# (Re)build the preprocessor using feature columns from X\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric),\n",
    "    (\"cat\", categorical_transformer, categorical)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34863f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=300),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=150, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"preprocess\", preprocessor), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results[name] = acc\n",
    "\n",
    "    print(\"\\n============================\")\n",
    "    print(name)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d56431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "knn_results = []\n",
    "for k in [3, 5, 11]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_pipe = Pipeline([(\"preprocess\", preprocessor), (\"model\", knn)])\n",
    "    knn_pipe.fit(X_train, y_train)\n",
    "    knn_preds = knn_pipe.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, knn_preds)\n",
    "    f1w = f1_score(y_test, knn_preds, average=\"weighted\")\n",
    "    knn_results.append((k, acc, f1w))\n",
    "\n",
    "    print(f\"\\n=== KNN (k={k}) ===\")\n",
    "    print(\"Accuracy:\", round(acc, 4), \" | F1(w):\", round(f1w, 4))\n",
    "    print(classification_report(y_test, knn_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc36bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== SUMMARY OF ALL MODELS (DATASET 1) ===\")\n",
    "print(f\"LogReg Accuracy:       {results['LogReg']:.4f}\")\n",
    "print(f\"RandomForest Accuracy: {results['RandomForest']:.4f}\")\n",
    "\n",
    "for k, acc, f1 in knn_results:\n",
    "    print(f\"KNN (k={k}) Accuracy:   {acc:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b0e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
